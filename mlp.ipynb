{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "tensor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcxvchT-VmcH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1becbcb-2927-4fd8-cf42-eea9bd85060a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from collections import Counter\n",
        "\n",
        "pd.options.mode.chained_assignment = 'warn'\n",
        "\n",
        "UNREST_COLUMNS = [\"EVENT_ID_CNTY\", \n",
        "                    \"EVENT_DATE\", \n",
        "                    \"EVENT_TYPE\", \n",
        "                    \"REGION\", \n",
        "                \"FATALITIES\",\n",
        "                \"TIMESTAMP\"]\n",
        "\n",
        "CASES_COLUMNS = [\"iso_code\",\n",
        "                \"continent\",\n",
        "                \"location\", \n",
        "                \"date\", \n",
        "                \"total_cases\", \n",
        "                \"new_cases\", \n",
        "                \"total_deaths\", \n",
        "                \"reproduction_rate\", \n",
        "                \"hosp_patients\", \n",
        "                \"positive_rate\", \n",
        "                \"stringency_index\", \n",
        "                \"population\",\n",
        "                \"median_age\",\n",
        "                \"gdp_per_capita\",\n",
        "                \"life_expectancy\",\n",
        "            ]\n",
        "\n",
        "def serialize(dataFrame, column):\n",
        "    return [x for x in range(len(dataFrame.loc[:, column].unique()))]\n",
        "\n",
        "def replaceDict(dataFrame, column):\n",
        "    vals = serialize(dataFrame, column)\n",
        "    return dict(zip(dataFrame.loc[:, column].unique(), vals))\n",
        "\n",
        "def multiSearch(df, column, searchTerms):\n",
        "    if type(searchTerms) is list:\n",
        "        return df.query(' | '.join(\n",
        "            [f'{column} == \"{term}\"' for term in searchTerms]\n",
        "        ))\n",
        "    elif type(searchTerms) is str:\n",
        "        return df.query(f'{column} == \"{searchTerms}\"')\n",
        "    else:\n",
        "        return df.query(f'{column} == {searchTerms}')\n",
        "\n",
        "def multiContains(df, column, searchTerms):\n",
        "    if type(searchTerms) is list:\n",
        "        return df[df.loc[:, column].str.contains('|'.join(searchTerms))]\n",
        "    else:\n",
        "        return df[df.loc[:, column].str.contains(searchTerms)]\n",
        "\n",
        "#Create the training data set of merged PD's and the result\n",
        "def retrieveTrainingData(isoCodes=None):\n",
        "    unrest_df = pd.read_csv(\"./coronavirus_Oct31.csv\")\n",
        "    unrest_df = unrest_df[unrest_df.loc[:, \"EVENT_TYPE\"] != 'Strategic developments']\n",
        " \n",
        "    covid_cases_df = pd.read_csv(\"./owid-covid-data.csv\")\n",
        "    covid_cases_df = covid_cases_df[covid_cases_df.loc[:, \"iso_code\"] != \"OWID_WRL\"]\n",
        "    covid_cases_df.dropna() \n",
        "\n",
        "    classes = unrest_df.EVENT_TYPE.unique()\n",
        "    print(classes)\n",
        "\n",
        "    unrest_df = unrest_df.loc[:, unrest_df.columns.intersection(UNREST_COLUMNS)]\n",
        "    covid_cases_df = covid_cases_df.loc[:, covid_cases_df.columns.intersection(CASES_COLUMNS)]\n",
        "\n",
        "    if (isoCodes == None):\n",
        "      unrest = unrest_df\n",
        "      cases = covid_cases_df\n",
        "    else:\n",
        "      unrest = multiContains(unrest_df, \"EVENT_ID_CNTY\", isoCodes)\n",
        "      cases = multiSearch(covid_cases_df, 'iso_code', isoCodes)\n",
        "\n",
        "    unrest.loc[:, \"EVENT_DATE\"] = pd.to_datetime(unrest.loc[:, \"EVENT_DATE\"])\n",
        "    cases.loc[:, \"date\"] = pd.to_datetime(cases.loc[:, \"date\"]) \n",
        "\n",
        "    merge = unrest.merge(cases, how=\"inner\", left_on=\"EVENT_DATE\", right_on=\"date\")\n",
        "\n",
        "    merge = merge.drop(['EVENT_ID_CNTY'], axis=1)\n",
        "    merge = merge.drop_duplicates()\n",
        "\n",
        "    issueType = merge['EVENT_TYPE']\n",
        "    issueType = issueType.replace(replaceDict(unrest_df, \"EVENT_TYPE\"))\n",
        "\n",
        "    merge = merge.drop(['EVENT_TYPE', 'EVENT_DATE', 'REGION', 'iso_code', 'continent', 'location', 'date', 'TIMESTAMP', \"FATALITIES\"], axis=1).fillna(0)\n",
        "\n",
        "    return merge, issueType, classes\n",
        "\n",
        "data, target, classes = retrieveTrainingData()\n",
        "\n",
        "print(Counter(target))\n",
        "print(len(target))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)\n",
        "\n",
        "print(Counter(y_train))\n",
        "#the data is fairly imbalanced so use random overfitting first to incrase ratios of minor classes\n",
        "# over_sampler = RandomOverSampler(sampling_strategy={2:78712, 4:78712})\n",
        "# under_sampler = RandomUnderSampler({0:111928, 1:105964})\n",
        "\n",
        "# X_train, y_train = over_sampler.fit_resample(X_train, y_train)\n",
        "# X_train, y_train = under_sampler.fit_resample(X_train, y_train)\n",
        "\n",
        "resampler = SMOTEENN()\n",
        "X_train, y_train = resampler.fit_resample(X_train, y_train)\n",
        "\n",
        "print(Counter(y_train))\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=5, alpha=1.0/5).fit(X_train, y_train)\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "print(\"training\\n\", classification_report(y_train, y_train_pred))\n",
        "print(confusion_matrix(y_train, y_train_pred))\n",
        "\n",
        "print(\"test\\n\", classification_report(y_test, y_test_pred))\n",
        "print(confusion_matrix(y_test, y_test_pred))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Protests' 'Riots' 'Battles' 'Violence against civilians'\n",
            " 'Explosions/Remote violence']\n",
            "Counter({0: 983573, 1: 265025, 3: 109838, 2: 15964, 4: 1869})\n",
            "1376269\n",
            "Counter({0: 786862, 1: 212039, 3: 87819, 2: 12785, 4: 1510})\n",
            "Counter({4: 660170, 2: 435824, 0: 221379, 3: 142334, 1: 78468})\n",
            "training\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.02      0.03    221379\n",
            "           1       0.00      0.00      0.00     78468\n",
            "           2       0.00      0.00      0.00    435824\n",
            "           3       0.00      0.00      0.00    142334\n",
            "           4       0.43      1.00      0.60    660170\n",
            "\n",
            "    accuracy                           0.43   1538175\n",
            "   macro avg       0.27      0.20      0.13   1538175\n",
            "weighted avg       0.32      0.43      0.26   1538175\n",
            "\n",
            "[[  3863      0      0      0 217516]\n",
            " [     2      0      0      0  78466]\n",
            " [     0      0      0      0 435824]\n",
            " [     0      0      0      0 142334]\n",
            " [   281      0      0      0 659889]]\n",
            "test\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.00      0.01    196711\n",
            "           1       0.00      0.00      0.00     52986\n",
            "           2       0.00      0.00      0.00      3179\n",
            "           3       0.00      0.00      0.00     22019\n",
            "           4       0.00      1.00      0.00       359\n",
            "\n",
            "    accuracy                           0.00    275254\n",
            "   macro avg       0.15      0.20      0.00    275254\n",
            "weighted avg       0.52      0.00      0.01    275254\n",
            "\n",
            "[[   954      0      0      0 195757]\n",
            " [   244      0      0      0  52742]\n",
            " [    18      0      0      0   3161]\n",
            " [   100      0      0      0  21919]\n",
            " [     1      0      0      0    358]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.rc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}