{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "tensor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcxvchT-VmcH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1becbcb-2927-4fd8-cf42-eea9bd85060a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.combine import SMOTEENN\n",
        "from collections import Counter\n",
        "import math\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "pd.options.mode.chained_assignment = 'warn'\n",
        "\n",
        "UNREST_COLUMNS = [\"EVENT_ID_CNTY\", \n",
        "                \"EVENT_DATE\", \n",
        "                \"EVENT_TYPE\", \n",
        "                \"REGION\", \n",
        "\n",
        "                \"TIMESTAMP\"]\n",
        "\n",
        "CASES_COLUMNS = [\"iso_code\",\n",
        "                \"continent\",\n",
        "                \"location\", \n",
        "                \"date\", \n",
        "                \"total_cases\", \n",
        "                \"new_cases\", \n",
        "                \"total_deaths\", \n",
        "                \"reproduction_rate\", \n",
        "                \"hosp_patients\", \n",
        "                \"positive_rate\", \n",
        "                \"stringency_index\", \n",
        "                \"population\",\n",
        "                \"median_age\",\n",
        "                \"gdp_per_capita\",\n",
        "                \"life_expectancy\",\n",
        "            ]\n",
        "def multiPrecision(y, y_pred, **kwargs):\n",
        "    return precision_score(y, y_pred, average=\"micro\", **kwargs)\n",
        "\n",
        "def multiRecall(y, y_pred, **kwargs):\n",
        "    return precision_score(y, y_pred, average=\"micro\", **kwargs)\n",
        "\n",
        "def serialize(dataFrame, column):\n",
        "    return [x for x in range(len(dataFrame[column].unique()))]\n",
        "\n",
        "#Replace a column in a dataframe with a serialized version\n",
        "def replaceDict(dataFrame, column):\n",
        "    vals = serialize(dataFrame, column)\n",
        "    return dict(zip(dataFrame[column].unique(), vals))\n",
        "\n",
        "def oneToOne(df, column):\n",
        "    count = []\n",
        "    ret = pd.DataFrame()\n",
        "    \n",
        "    count = [{\"col\": val, \"count\": df[df[column] == val].shape[0]} for val in df[column].unique()]\n",
        "    count.sort(key=lambda x: x.get(\"count\"))\n",
        "    i = 1\n",
        "    for col in count:\n",
        "        if ret.empty:\n",
        "            ret = pd.DataFrame(df[df[column] == col.get(\"col\")].sample(math.floor(count[0].get(\"count\") * i), replace=True).drop_duplicates())\n",
        "        else:\n",
        "            ret = ret.append(df[df[column] == col.get(\"col\")].sample(math.floor(count[0].get(\"count\") * i), replace=True).drop_duplicates())\n",
        "        i = i + 10\n",
        "    return ret\n",
        "\n",
        "def manyToOne(df, column):\n",
        "    count = []\n",
        "    ret = pd.DataFrame()\n",
        "    \n",
        "    count = [df[df[column] == val].shape[0] for val in df[column].unique()]\n",
        "    count.sort()\n",
        "\n",
        "def randomSample(one=True):\n",
        "    #Read in data from files\n",
        "    unrest_df = pd.read_csv(\"./coronavirus_Oct31.csv\")\n",
        "    #Remove rows with event type of strategic developments\n",
        "    unrest_df = unrest_df[unrest_df.EVENT_TYPE != 'Strategic developments']\n",
        " \n",
        "    covid_cases_df = pd.read_csv(\"./owid-covid-data.csv\")\n",
        "\n",
        "    unrest_df = unrest_df[unrest_df.columns.intersection(UNREST_COLUMNS)]\n",
        "    covid_cases_df = covid_cases_df[covid_cases_df.columns.intersection(CASES_COLUMNS)]\n",
        "    #Get data based on the input iso country codes\n",
        "    #unrest = multiContains(unrest_df, \"EVENT_ID_CNTY\", isoCodes)\n",
        "    #cases = multiSearch(covid_cases_df, 'iso_code', isoCodes)\n",
        "\n",
        "    #Convert \"date\" type columns to dates\n",
        "    unrest_df.EVENT_DATE = pd.to_datetime(unrest_df.EVENT_DATE)\n",
        "    unrest_df.EVENT_ID_CNTY = unrest_df.EVENT_ID_CNTY.astype(str).str[:3]\n",
        "    covid_cases_df.date = pd.to_datetime(covid_cases_df.date)\n",
        "    #Merge the two datasets with an inner join on the date fields\n",
        "    merge = unrest_df.merge(covid_cases_df, how=\"inner\", left_on=[\"EVENT_DATE\", 'EVENT_ID_CNTY'], right_on=[\"date\", \"iso_code\"])\n",
        "    #merge = merge.drop_duplicates(subset=['EVENT_DATE', 'EVENT_ID_CNTY'])\n",
        "    #Drop the iso code to avoid duplicates\n",
        "    \n",
        "    merge = merge.drop(['EVENT_ID_CNTY'], axis=1)\n",
        "    #Drop remaining duplicates\n",
        "    #merge = merge.drop_duplicates()\n",
        "    print(merge.shape)\n",
        "    #Get the list of event types in this particular set of data\n",
        "    #issueType = merge['EVENT_TYPE']\n",
        "    #Serialize the data and return it as the expected values for training\n",
        "    #issueType = issueType.replace(replaceDict(unrest_df, \"EVENT_TYPE\"))\n",
        "    result = pd.DataFrame()\n",
        "    if one:\n",
        "        result = oneToOne(merge, 'EVENT_TYPE')\n",
        "    else:\n",
        "        result = merge\n",
        "    issueType = result['EVENT_TYPE']\n",
        "    #Serialize the data and return it as the expected values for training\n",
        "    issueType = issueType.replace(replaceDict(unrest_df, \"EVENT_TYPE\"))\n",
        "\n",
        "    #Drop remaining unneeded data\n",
        "    result = result.drop(['EVENT_TYPE', 'EVENT_DATE', 'REGION', 'iso_code', 'continent', 'location', 'date', 'TIMESTAMP'], axis=1).fillna(0)\n",
        "\n",
        "    return result, issueType\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "X, y = randomSample(False)\n",
        "X = min_max_scaler.fit_transform(X)\n",
        "\n",
        "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "resampler = SMOTEENN()\n",
        "X_train, y_train = resampler.fit_resample(X_train, y_train)\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=5, alpha=1.0/5).fit(X_train, y_train)\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "print(\"training\\n\", classification_report(issueType, y_train_pred))\n",
        "print(confusion_matrix(y_train, y_train_pred))\n",
        "\n",
        "print(\"test\\n\", classification_report(testIssues, y_test_pred))\n",
        "print(confusion_matrix(y_test, y_test_pred))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14596, 19)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unknown label type: 'continuous-multioutput'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d280f81e28af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mresampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    171\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous-multioutput'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.rc()"
      ]
    }
  ]
}