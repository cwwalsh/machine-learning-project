{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "\n",
    "def serialize(dataFrame, column):\n",
    "    return [x for x in range(len(dataFrame[column].unique()))]\n",
    "\n",
    "def replaceDict(dataFrame, column):\n",
    "    vals = serialize(dataFrame, column)\n",
    "    return dict(zip(dataFrame[column].unique(), vals))\n",
    "\n",
    "\n",
    "\n",
    "def multiSearch(df, column, searchTerms):\n",
    "    if type(searchTerms) is list:\n",
    "        return df.query(' | '.join(\n",
    "            [f'{column} == \"{term}\"' for term in searchTerms]\n",
    "        ))\n",
    "    elif type(searchTerms) is str:\n",
    "        return df.query(f'{column} == \"{searchTerms}\"')\n",
    "    else:\n",
    "        return df.query(f'{column} == {searchTerms}')\n",
    "\n",
    "def multiContains(df, column, searchTerms):\n",
    "    if type(searchTerms) is list:\n",
    "        return df[df[column].str.contains('|'.join(searchTerms))]\n",
    "    else:\n",
    "        return df[df[column].str.contains(searchTerms)]\n",
    "\n",
    "\n",
    "UNREST_COLUMNS = [\"EVENT_ID_CNTY\", \n",
    "                    \"EVENT_DATE\", \n",
    "                    \"EVENT_TYPE\", \n",
    "                    \"REGION\", \n",
    "                \"FATALITIES\"]\n",
    "\n",
    "CASES_COLUMNS = [\"iso_code\",\n",
    "                \"continent\",\n",
    "                \"location\", \n",
    "                \"date\", \n",
    "                \"total_cases\", \n",
    "                \"new_cases\", \n",
    "                \"total_deaths\", \n",
    "                \"reproduction_rate\", \n",
    "                \"hosp_patients\", \n",
    "                \"positive_rate\", \n",
    "                \"stringency_index\", \n",
    "                \"population\",\n",
    "                \"median_age\",\n",
    "                \"gdp_per_capita\",\n",
    "                \"life_expectancy\"\n",
    "            ]\n",
    "\n",
    "unrest_df = pd.read_csv(\"./coronavirus_Oct31.csv\")\n",
    "covid_cases_df = pd.read_csv(\"./owid-covid-data.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "unrest_df = unrest_df[unrest_df.columns.intersection(UNREST_COLUMNS)]\n",
    "covid_cases_df = covid_cases_df[covid_cases_df.columns.intersection(CASES_COLUMNS)]\n",
    "\n",
    "irl_afg = multiSearch(covid_cases_df, 'iso_code', ['AFG', 'IRL'])\n",
    "\n",
    "irl_afg_unrest = multiContains(unrest_df, \"EVENT_ID_CNTY\", ['AFG', 'IRL'])\n",
    "\n",
    "\n",
    "unrest_afg = multiContains(unrest_df,\"EVENT_ID_CNTY\",\"AFG\")\n",
    "\n",
    "cases_afg = multiSearch(covid_cases_df, 'iso_code', \"AFG\")\n",
    "\n",
    "unrest_afg.EVENT_DATE = pd.to_datetime(unrest_afg.EVENT_DATE)\n",
    "cases_afg.date = pd.to_datetime(cases_afg.date)\n",
    "\n",
    "merge = unrest_afg.merge(cases_afg, how=\"inner\", left_on=\"EVENT_DATE\", right_on=\"date\")\n",
    "\n",
    "classification = serialize(unrest_df, \"EVENT_TYPE\")\n",
    "\n",
    "issueType = unrest_afg['EVENT_TYPE']\n",
    "issueType = issueType.replace(replaceDict(unrest_df, \"EVENT_TYPE\"))\n",
    "\n",
    "merge = merge.drop(['EVENT_TYPE', 'EVENT_DATE', 'EVENT_ID_CNTY', 'REGION', 'iso_code', 'continent', 'location', 'date'], axis=1).fillna(0)\n",
    "# print(merge)\n",
    "# mergeNormal = normalize(merge)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "mergeNormal = min_max_scaler.fit_transform(merge)\n",
    "mergeNormal = pd.DataFrame(mergeNormal)\n",
    "mergeNormal\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(mergeNormal, issueType)\n",
    "# print(issueType)\n",
    "clf.predict(mergeNormal)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     EVENT_ID_CNTY       EVENT_DATE              EVENT_TYPE  \\\n24        AFG44949    22-March-2020  Strategic developments   \n25        AFG44932    25-March-2020  Strategic developments   \n26        AFG44930    25-March-2020  Strategic developments   \n27        AFG44931    25-March-2020  Strategic developments   \n28        AFG44951    26-March-2020  Strategic developments   \n...            ...              ...                     ...   \n1248       ARG3568  30-October-2020                Protests   \n1249       ARG3570  31-October-2020                Protests   \n1250       ARG3571  31-October-2020                   Riots   \n1251       ARG3572  31-October-2020                Protests   \n1252       ARG3569  31-October-2020                Protests   \n\n                         REGION  FATALITIES   TIMESTAMP  \n24    Caucasus and Central Asia           0  1586190074  \n25    Caucasus and Central Asia           0  1586190085  \n26    Caucasus and Central Asia           0  1586190085  \n27    Caucasus and Central Asia           0  1586190085  \n28    Caucasus and Central Asia           0  1586190074  \n...                         ...         ...         ...  \n1248              South America           0  1604354024  \n1249              South America           0  1604354024  \n1250              South America           0  1604354024  \n1251              South America           0  1604354023  \n1252              South America           0  1604354023  \n\n[937 rows x 6 columns]\n0.8898071625344353\n0.9039039039039038\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def serialize(dataFrame, column):\n",
    "    return [x for x in range(len(dataFrame[column].unique()))]\n",
    "\n",
    "def replaceDict(dataFrame, column):\n",
    "    vals = serialize(dataFrame, column)\n",
    "    return dict(zip(dataFrame[column].unique(), vals))\n",
    "\n",
    "\n",
    "\n",
    "def multiSearch(df, column, searchTerms):\n",
    "    if type(searchTerms) is list:\n",
    "        return df.query(' | '.join(\n",
    "            [f'{column} == \"{term}\"' for term in searchTerms]\n",
    "        ))\n",
    "    elif type(searchTerms) is str:\n",
    "        return df.query(f'{column} == \"{searchTerms}\"')\n",
    "    else:\n",
    "        return df.query(f'{column} == {searchTerms}')\n",
    "\n",
    "def multiContains(df, column, searchTerms):\n",
    "    if type(searchTerms) is list:\n",
    "        return df[df[column].str.contains('|'.join(searchTerms))]\n",
    "    else:\n",
    "        return df[df[column].str.contains(searchTerms)]\n",
    "\n",
    "\n",
    "UNREST_COLUMNS = [\"EVENT_ID_CNTY\", \n",
    "                    \"EVENT_DATE\", \n",
    "                    \"EVENT_TYPE\", \n",
    "                    \"REGION\", \n",
    "                \"FATALITIES\",\n",
    "                \"TIMESTAMP\"]\n",
    "\n",
    "CASES_COLUMNS = [\"iso_code\",\n",
    "                \"continent\",\n",
    "                \"location\", \n",
    "                \"date\", \n",
    "                \"total_cases\", \n",
    "                \"new_cases\", \n",
    "                \"total_deaths\", \n",
    "                \"reproduction_rate\", \n",
    "                \"hosp_patients\", \n",
    "                \"positive_rate\", \n",
    "                \"stringency_index\", \n",
    "                \"population\",\n",
    "                \"median_age\",\n",
    "                \"gdp_per_capita\",\n",
    "                \"life_expectancy\",\n",
    "            ]\n",
    "\n",
    "unrest_df = pd.read_csv(\"./coronavirus_Oct31.csv\")\n",
    "covid_cases_df = pd.read_csv(\"./owid-covid-data.csv\")\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "unrest_df = unrest_df[unrest_df.columns.intersection(UNREST_COLUMNS)]\n",
    "covid_cases_df = covid_cases_df[covid_cases_df.columns.intersection(CASES_COLUMNS)]\n",
    "\n",
    "afg_unrest = multiContains(unrest_df, \"EVENT_ID_CNTY\", 'ARG')\n",
    "afg = multiSearch(covid_cases_df, 'iso_code', 'ARG')\n",
    "\n",
    "afg_unrest.EVENT_DATE = pd.to_datetime(unrest_afg.EVENT_DATE)\n",
    "afg.date = pd.to_datetime(cases_afg.date)\n",
    "\n",
    "merge2 = afg_unrest.merge(afg, how=\"inner\", left_on=\"EVENT_DATE\", right_on=\"date\")\n",
    "\n",
    "\n",
    "merge2 = merge2.drop(['EVENT_ID_CNTY'], axis=1)\n",
    "merge2 = merge2.drop_duplicates()\n",
    "\n",
    "issueType2 = merge2['EVENT_TYPE']\n",
    "issueType2 = issueType2.replace(replaceDict(unrest_df, \"EVENT_TYPE\"))\n",
    "\n",
    "merge2 = merge2.drop(['EVENT_TYPE', 'EVENT_DATE', 'REGION', 'iso_code', 'continent', 'location', 'date'], axis=1).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "mergeNormal2 = min_max_scaler.fit_transform(merge2)\n",
    "mergeNormal2 = pd.DataFrame(mergeNormal2)\n",
    "\n",
    "\n",
    "unrest_afg = multiContains(unrest_df,\"EVENT_ID_CNTY\",['AFG','ARG'])\n",
    "cases_afg = multiSearch(covid_cases_df, 'iso_code', ['AFG','ARG'])\n",
    "print(unrest_afg)\n",
    "unrest_afg.EVENT_DATE = pd.to_datetime(unrest_afg.EVENT_DATE)\n",
    "cases_afg.date = pd.to_datetime(cases_afg.date)\n",
    "\n",
    "merge = unrest_afg.merge(cases_afg, how=\"inner\", left_on=\"EVENT_DATE\", right_on=\"date\")\n",
    "\n",
    "classification = serialize(unrest_df, \"EVENT_TYPE\")\n",
    "\n",
    "merge = merge.drop(['EVENT_ID_CNTY'], axis=1)\n",
    "merge = merge.drop_duplicates()\n",
    "\n",
    "issueType = merge['EVENT_TYPE']\n",
    "#print(unrest_afg)\n",
    "issueType = issueType.replace(replaceDict(unrest_df, \"EVENT_TYPE\"))\n",
    "\n",
    "merge = merge.drop(['EVENT_TYPE', 'EVENT_DATE', 'REGION', 'iso_code', 'continent', 'location', 'date'], axis=1).fillna(0)\n",
    "# print(merge)\n",
    "# mergeNormal = normalize(merge)\n",
    "\n",
    "\n",
    "mergeNormal = min_max_scaler.fit_transform(merge)\n",
    "mergeNormal = pd.DataFrame(mergeNormal)\n",
    "mergeNormal\n",
    "\n",
    "#clf = svm.SVC()\n",
    "#print(issueType)\n",
    "#clf.fit(mergeNormal, issueType)\n",
    "\n",
    "#clf.predict(mergeNormal)\n",
    "\n",
    "dTree = DecisionTreeClassifier(max_depth=5)\n",
    "dTree.fit(mergeNormal, issueType)\n",
    "pred = dTree.predict(mergeNormal)\n",
    "pred2 = dTree.predict(mergeNormal2)\n",
    "print(precision_score(issueType, pred, average=\"micro\"))\n",
    "print(precision_score(issueType2, pred2, average=\"micro\"))\n",
    "\n",
    "\n"
   ]
  }
 ]
}