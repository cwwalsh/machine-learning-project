{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "\n",
    "def serialize(dataFrame, column):\n",
    "    return [x for x in range(len(dataFrame[column].unique()))]\n",
    "\n",
    "def replaceDict(dataFrame, column):\n",
    "    vals = serialize(dataFrame, column)\n",
    "    return dict(zip(dataFrame[column].unique(), vals))\n",
    "\n",
    "\n",
    "\n",
    "def multiSearch(df, column, searchTerms):\n",
    "    if type(searchTerms) is list:\n",
    "        return df.query(' | '.join(\n",
    "            [f'{column} == \"{term}\"' for term in searchTerms]\n",
    "        ))\n",
    "    elif type(searchTerms) is str:\n",
    "        return df.query(f'{column} == \"{searchTerms}\"')\n",
    "    else:\n",
    "        return df.query(f'{column} == {searchTerms}')\n",
    "\n",
    "def multiContains(df, column, searchTerms):\n",
    "    if type(searchTerms) is list:\n",
    "        return df[df[column].str.contains('|'.join(searchTerms))]\n",
    "    else:\n",
    "        return df[df[column].str.contains(searchTerms)]\n",
    "\n",
    "\n",
    "UNREST_COLUMNS = [\"EVENT_ID_CNTY\", \n",
    "                    \"EVENT_DATE\", \n",
    "                    \"EVENT_TYPE\", \n",
    "                    \"REGION\", \n",
    "                \"FATALITIES\"]\n",
    "\n",
    "CASES_COLUMNS = [\"iso_code\",\n",
    "                \"continent\",\n",
    "                \"location\", \n",
    "                \"date\", \n",
    "                \"total_cases\", \n",
    "                \"new_cases\", \n",
    "                \"total_deaths\", \n",
    "                \"reproduction_rate\", \n",
    "                \"hosp_patients\", \n",
    "                \"positive_rate\", \n",
    "                \"stringency_index\", \n",
    "                \"population\",\n",
    "                \"median_age\",\n",
    "                \"gdp_per_capita\",\n",
    "                \"life_expectancy\"\n",
    "            ]\n",
    "\n",
    "unrest_df = pd.read_csv(\"./coronavirus_Oct31.csv\")\n",
    "covid_cases_df = pd.read_csv(\"./owid-covid-data.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "unrest_df = unrest_df[unrest_df.columns.intersection(UNREST_COLUMNS)]\n",
    "covid_cases_df = covid_cases_df[covid_cases_df.columns.intersection(CASES_COLUMNS)]\n",
    "\n",
    "irl_afg = multiSearch(covid_cases_df, 'iso_code', ['AFG', 'IRL'])\n",
    "\n",
    "irl_afg_unrest = multiContains(unrest_df, \"EVENT_ID_CNTY\", ['AFG', 'IRL'])\n",
    "\n",
    "\n",
    "unrest_afg = multiContains(unrest_df,\"EVENT_ID_CNTY\",\"AFG\")\n",
    "\n",
    "cases_afg = multiSearch(covid_cases_df, 'iso_code', \"AFG\")\n",
    "\n",
    "unrest_afg.EVENT_DATE = pd.to_datetime(unrest_afg.EVENT_DATE)\n",
    "cases_afg.date = pd.to_datetime(cases_afg.date)\n",
    "\n",
    "merge = unrest_afg.merge(cases_afg, how=\"inner\", left_on=\"EVENT_DATE\", right_on=\"date\")\n",
    "\n",
    "classification = serialize(unrest_df, \"EVENT_TYPE\")\n",
    "\n",
    "issueType = unrest_afg['EVENT_TYPE']\n",
    "issueType = issueType.replace(replaceDict(unrest_df, \"EVENT_TYPE\"))\n",
    "\n",
    "merge = merge.drop(['EVENT_TYPE', 'EVENT_DATE', 'EVENT_ID_CNTY', 'REGION', 'iso_code', 'continent', 'location', 'date'], axis=1).fillna(0)\n",
    "# print(merge)\n",
    "# mergeNormal = normalize(merge)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "mergeNormal = min_max_scaler.fit_transform(merge)\n",
    "mergeNormal = pd.DataFrame(mergeNormal)\n",
    "mergeNormal\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(mergeNormal, issueType)\n",
    "# print(issueType)\n",
    "clf.predict(mergeNormal)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8898071625344353\n0.9039039039039038\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def serialize(dataFrame, column):\n",
    "    return [x for x in range(len(dataFrame[column].unique()))]\n",
    "\n",
    "def replaceDict(dataFrame, column):\n",
    "    vals = serialize(dataFrame, column)\n",
    "    return dict(zip(dataFrame[column].unique(), vals))\n",
    "\n",
    "def multiSearch(df, column, searchTerms):\n",
    "    if type(searchTerms) is list:\n",
    "        return df.query(' | '.join(\n",
    "            [f'{column} == \"{term}\"' for term in searchTerms]\n",
    "        ))\n",
    "    elif type(searchTerms) is str:\n",
    "        return df.query(f'{column} == \"{searchTerms}\"')\n",
    "    else:\n",
    "        return df.query(f'{column} == {searchTerms}')\n",
    "\n",
    "def multiContains(df, column, searchTerms):\n",
    "    if type(searchTerms) is list:\n",
    "        return df[df[column].str.contains('|'.join(searchTerms))]\n",
    "    else:\n",
    "        return df[df[column].str.contains(searchTerms)]\n",
    "\n",
    "def retrieveTrainingData(unrest, cases):\n",
    "    unrest_df = pd.read_csv(\"./coronavirus_Oct31.csv\")\n",
    "    covid_cases_df = pd.read_csv(\"./owid-covid-data.csv\")\n",
    "\n",
    "\n",
    "UNREST_COLUMNS = [\"EVENT_ID_CNTY\", \n",
    "                    \"EVENT_DATE\", \n",
    "                    \"EVENT_TYPE\", \n",
    "                    \"REGION\", \n",
    "                \"FATALITIES\",\n",
    "                \"TIMESTAMP\"]\n",
    "\n",
    "CASES_COLUMNS = [\"iso_code\",\n",
    "                \"continent\",\n",
    "                \"location\", \n",
    "                \"date\", \n",
    "                \"total_cases\", \n",
    "                \"new_cases\", \n",
    "                \"total_deaths\", \n",
    "                \"reproduction_rate\", \n",
    "                \"hosp_patients\", \n",
    "                \"positive_rate\", \n",
    "                \"stringency_index\", \n",
    "                \"population\",\n",
    "                \"median_age\",\n",
    "                \"gdp_per_capita\",\n",
    "                \"life_expectancy\",\n",
    "            ]\n",
    "\n",
    "\n",
    "\n",
    "unrest_df = pd.read_csv(\"./coronavirus_Oct31.csv\")\n",
    "covid_cases_df = pd.read_csv(\"./owid-covid-data.csv\")\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "unrest_df = unrest_df[unrest_df.columns.intersection(UNREST_COLUMNS)]\n",
    "covid_cases_df = covid_cases_df[covid_cases_df.columns.intersection(CASES_COLUMNS)]\n",
    "\n",
    "afg_unrest = multiContains(unrest_df, \"EVENT_ID_CNTY\", 'ARG')\n",
    "afg = multiSearch(covid_cases_df, 'iso_code', 'ARG')\n",
    "\n",
    "afg_unrest.EVENT_DATE = pd.to_datetime(afg_unrest.EVENT_DATE)\n",
    "afg.date = pd.to_datetime(afg.date)\n",
    "\n",
    "merge2 = afg_unrest.merge(afg, how=\"inner\", left_on=\"EVENT_DATE\", right_on=\"date\")\n",
    "\n",
    "\n",
    "merge2 = merge2.drop(['EVENT_ID_CNTY'], axis=1)\n",
    "merge2 = merge2.drop_duplicates()\n",
    "\n",
    "issueType2 = merge2['EVENT_TYPE']\n",
    "issueType2 = issueType2.replace(replaceDict(unrest_df, \"EVENT_TYPE\"))\n",
    "\n",
    "merge2 = merge2.drop(['EVENT_TYPE', 'EVENT_DATE', 'REGION', 'iso_code', 'continent', 'location', 'date'], axis=1).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "mergeNormal2 = min_max_scaler.fit_transform(merge2)\n",
    "mergeNormal2 = pd.DataFrame(mergeNormal2)\n",
    "\n",
    "\n",
    "unrest_afg = multiContains(unrest_df,\"EVENT_ID_CNTY\",['AFG','ARG'])\n",
    "cases_afg = multiSearch(covid_cases_df, 'iso_code', ['AFG','ARG'])\n",
    "# print(unrest_afg)\n",
    "unrest_afg.EVENT_DATE = pd.to_datetime(unrest_afg.EVENT_DATE)\n",
    "cases_afg.date = pd.to_datetime(cases_afg.date)\n",
    "\n",
    "merge = unrest_afg.merge(cases_afg, how=\"inner\", left_on=\"EVENT_DATE\", right_on=\"date\")\n",
    "\n",
    "classification = serialize(unrest_df, \"EVENT_TYPE\")\n",
    "\n",
    "merge = merge.drop(['EVENT_ID_CNTY'], axis=1)\n",
    "merge = merge.drop_duplicates()\n",
    "\n",
    "issueType = merge['EVENT_TYPE']\n",
    "\n",
    "issueType = issueType.replace(replaceDict(unrest_df, \"EVENT_TYPE\"))\n",
    "\n",
    "merge = merge.drop(['EVENT_TYPE', 'EVENT_DATE', 'REGION', 'iso_code', 'continent', 'location', 'date'], axis=1).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "mergeNormal = min_max_scaler.fit_transform(merge)\n",
    "mergeNormal = pd.DataFrame(mergeNormal)\n",
    "mergeNormal\n",
    "\n",
    "#clf = svm.SVC()\n",
    "#print(issueType)\n",
    "#clf.fit(mergeNormal, issueType)\n",
    "\n",
    "#clf.predict(mergeNormal)\n",
    "\n",
    "dTree = DecisionTreeClassifier(max_depth=5)\n",
    "dTree.fit(mergeNormal, issueType)\n",
    "pred = dTree.predict(mergeNormal)\n",
    "pred2 = dTree.predict(mergeNormal2)\n",
    "print(precision_score(issueType, pred, average=\"micro\"))\n",
    "print(precision_score(issueType2, pred2, average=\"micro\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Strategic developments' 'Protests' 'Riots' 'Battles'\n",
      " 'Violence against civilians' 'Explosions/Remote violence']\n",
      "['Strategic developments' 'Protests' 'Riots' 'Battles'\n",
      " 'Violence against civilians' 'Explosions/Remote violence']\n",
      "['Strategic developments' 'Protests' 'Riots' 'Battles'\n",
      " 'Violence against civilians' 'Explosions/Remote violence']\n",
      "Decision tree\n",
      "0.8622589531680441\n",
      "0.7626262626262627\n",
      "Ridge\n",
      "0.837465564738292\n",
      "0.803030303030303\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "\n",
    "UNREST_COLUMNS = [\"EVENT_ID_CNTY\", \n",
    "                    \"EVENT_DATE\", \n",
    "                    \"EVENT_TYPE\", \n",
    "                    \"REGION\", \n",
    "                \"FATALITIES\",\n",
    "                \"TIMESTAMP\"]\n",
    "\n",
    "CASES_COLUMNS = [\"iso_code\",\n",
    "                \"continent\",\n",
    "                \"location\", \n",
    "                \"date\", \n",
    "                \"total_cases\", \n",
    "                \"new_cases\", \n",
    "                \"total_deaths\", \n",
    "                \"reproduction_rate\", \n",
    "                \"hosp_patients\", \n",
    "                \"positive_rate\", \n",
    "                \"stringency_index\", \n",
    "                \"population\",\n",
    "                \"median_age\",\n",
    "                \"gdp_per_capita\",\n",
    "                \"life_expectancy\",\n",
    "            ]\n",
    "\n",
    "def serialize(dataFrame, column):\n",
    "    return [x for x in range(len(dataFrame[column].unique()))]\n",
    "\n",
    "def replaceDict(dataFrame, column):\n",
    "    vals = serialize(dataFrame, column)\n",
    "    return dict(zip(dataFrame[column].unique(), vals))\n",
    "\n",
    "def multiSearch(df, column, searchTerms):\n",
    "    if type(searchTerms) is list:\n",
    "        return df.query(' | '.join(\n",
    "            [f'{column} == \"{term}\"' for term in searchTerms]\n",
    "        ))\n",
    "    elif type(searchTerms) is str:\n",
    "        return df.query(f'{column} == \"{searchTerms}\"')\n",
    "    else:\n",
    "        return df.query(f'{column} == {searchTerms}')\n",
    "\n",
    "def multiContains(df, column, searchTerms):\n",
    "    if type(searchTerms) is list:\n",
    "        return df[df[column].str.contains('|'.join(searchTerms))]\n",
    "    else:\n",
    "        return df[df[column].str.contains(searchTerms)]\n",
    "\n",
    "#Create the training data set of merged PD's and the result\n",
    "def retrieveTrainingData(isoCodes):\n",
    "    unrest_df = pd.read_csv(\"./coronavirus_Oct31.csv\")\n",
    "    unrest_df = unrest_df[unrest_df.EVENT_TYPE != 'Strategic developments']\n",
    " \n",
    "    covid_cases_df = pd.read_csv(\"./owid-covid-data.csv\")\n",
    "    print(unrest_df.EVENT_TYPE.unique())\n",
    "\n",
    "    unrest_df = unrest_df[unrest_df.columns.intersection(UNREST_COLUMNS)]\n",
    "    covid_cases_df = covid_cases_df[covid_cases_df.columns.intersection(CASES_COLUMNS)]\n",
    "\n",
    "    unrest = multiContains(unrest_df, \"EVENT_ID_CNTY\", isoCodes)\n",
    "    cases = multiSearch(covid_cases_df, 'iso_code', isoCodes)\n",
    "\n",
    "    unrest.EVENT_DATE = pd.to_datetime(unrest.EVENT_DATE)\n",
    "    cases.date = pd.to_datetime(cases.date) \n",
    "\n",
    "    merge = unrest.merge(cases, how=\"inner\", left_on=\"EVENT_DATE\", right_on=\"date\")\n",
    "\n",
    "    merge = merge.drop(['EVENT_ID_CNTY'], axis=1)\n",
    "    merge = merge.drop_duplicates()\n",
    "\n",
    "    issueType = merge['EVENT_TYPE']\n",
    "    issueType = issueType.replace(replaceDict(unrest_df, \"EVENT_TYPE\"))\n",
    "\n",
    "\n",
    "    merge = merge.drop(['EVENT_TYPE', 'EVENT_DATE', 'REGION', 'iso_code', 'continent', 'location', 'date', 'TIMESTAMP'], axis=1).fillna(0)\n",
    "\n",
    "    return merge, issueType\n",
    "\n",
    "\n",
    "merge2, issueType2 = retrieveTrainingData(['BOL'])\n",
    "\n",
    "mergeNormal2 = min_max_scaler.fit_transform(merge2)\n",
    "mergeNormal2 = pd.DataFrame(mergeNormal2)\n",
    "\n",
    "merge, issueType = retrieveTrainingData(['AFG','ARG', 'BDG'])\n",
    "\n",
    "mergeNormal = min_max_scaler.fit_transform(merge)\n",
    "mergeNormal = pd.DataFrame(mergeNormal)\n",
    "mergeNormal\n",
    "\n",
    "X, y = retrieveTrainingData('AFG')\n",
    "#clf = svm.SVC()\n",
    "#print(issueType)\n",
    "#clf.fit(mergeNormal, issueType)\n",
    "\n",
    "#clf.predict(mergeNormal)\n",
    "\n",
    "dTree = DecisionTreeClassifier(max_depth=5)\n",
    "dTree.fit(mergeNormal, issueType)\n",
    "pred = dTree.predict(mergeNormal)\n",
    "pred2 = dTree.predict(mergeNormal2)\n",
    "print(\"Decision tree\")\n",
    "print(precision_score(issueType, pred, average=\"micro\"))\n",
    "print(precision_score(issueType2, pred2, average=\"micro\"))\n",
    "\n",
    "ridge = RidgeClassifier()\n",
    "ridge.fit(mergeNormal, issueType)\n",
    "ridgePred = ridge.predict(mergeNormal)\n",
    "ridgePredGen = ridge.predict(mergeNormal2)\n",
    "print(\"Ridge\")\n",
    "print(precision_score(issueType, ridgePred, average=\"micro\"))\n",
    "print(precision_score(issueType2, ridgePredGen, average=\"micro\"))\n"
   ]
  }
 ]
}